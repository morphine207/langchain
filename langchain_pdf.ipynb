{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d685906",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"unstructured[local-inference]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f94822",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518b63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de24688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/morphine/Desktop/lang', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/morphine/.local/lib/python3.10/site-packages', '/home/morphine/aries-cloudagent-python', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410e4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('<path_to_langchain_installation>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f3ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e148776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a674b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")\n",
    "#loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1307db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e92ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed1b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 201014 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dbed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de51668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209873d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 240 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcb5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83f03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d227b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3aaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8b96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '...'\n",
    "PINECONE_API_KEY = '...'\n",
    "PINECONE_API_ENV = 'us-east4-gcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28b1549",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8840f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4524cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb9e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are examples of good data science teams?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e372da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee0328a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2779cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0bd03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Could you please explain me about model validation?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9edcfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Model validation is the process of assessing how well a model fits the observed data. It is used to answer the question “How well did my hypothesis fit the observed data?” To validate a model, the data is usually split into training, testing and validation sets. The model is constructed with the training data and then evaluated with the testing data. The performance of the model against the testing set is used to further reduce model error. Finally, the model is evaluated on the validation data to assess how well the model generalizes. Statistical methods such as calculating the coefficient of determination, commonly called the R-squared value, are also used to validate models.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30eddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
