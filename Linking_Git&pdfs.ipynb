{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521c6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.docstore.document import Document\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bb9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22f07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b206851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0))\n",
    "\n",
    "def print_answer(question):\n",
    "    print(\n",
    "        chain(\n",
    "            {\n",
    "                \"input_documents\": search_index.similarity_search(question, k=4),\n",
    "                \"question\": question,\n",
    "            },\n",
    "            return_only_outputs=True,\n",
    "        )[\"output_text\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4f9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import subprocess\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48bf3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_github_docs(repo_owner, repo_name):\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        subprocess.check_call(\n",
    "            f\"git clone --depth 1 https://github.com/{repo_owner}/{repo_name}.git .\",\n",
    "            cwd=d,\n",
    "            shell=True,\n",
    "        )\n",
    "        git_sha = (\n",
    "            subprocess.check_output(\"git rev-parse HEAD\", shell=True, cwd=d)\n",
    "            .decode(\"utf-8\")\n",
    "            .strip()\n",
    "        )\n",
    "        repo_path = pathlib.Path(d)\n",
    "        markdown_files = list(repo_path.glob(\"*/*.md\")) + list(\n",
    "            repo_path.glob(\"*/*.mdx\")\n",
    "        )\n",
    "        for markdown_file in markdown_files:\n",
    "            with open(markdown_file, \"r\") as f:\n",
    "                relative_path = markdown_file.relative_to(repo_path)\n",
    "                github_url = f\"https://github.com/{repo_owner}/{repo_name}/blob/{git_sha}/{relative_path}\"\n",
    "                yield Document(page_content=f.read(), metadata={\"source\": github_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fefe1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '.'...\n"
     ]
    }
   ],
   "source": [
    "repo_owner = \"hyperledger\"\n",
    "repo_name = \"aries-cloudagent-python\"\n",
    "\n",
    "documents = list(get_github_docs(repo_owner, repo_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebaf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc.page_content for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2c3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ad1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    page_content: str\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "\n",
    "# Assuming `texts` is a list of strings from GitHub repo\n",
    "documents = [Document(page_content=text) for text in texts]\n",
    "split_texts = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b8781d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 170 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(split_texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf039a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68de9aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morphine/.local/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c182491",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '...'\n",
    "PINECONE_API_KEY = '...'\n",
    "PINECONE_API_ENV = 'us-east4-gcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aab4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b59f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b857b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e5d72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in split_texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1ccd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef6d8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36a2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Could you please explain me about model validation?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "496757cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Model validation is the process of assessing how well a model fits the observed data. It is used to answer the question “How well did my hypothesis fit the observed data?” To validate a model, the data is usually split into training, testing and validation sets. The model is constructed with the training data and then evaluated with the testing data. The performance of the model against the testing set is used to further reduce model error. Finally, the model is evaluated on the validation data to assess how well the model generalizes. Statistical methods such as calculating the coefficient of determination, commonly called the R-squared value, are also used to validate models.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "785bcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you summarize the raw data?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "333ca1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' No, raw data cannot be summarized. It must first be collected or processed in order to assess its truthfulness and accuracy, identify missing or incomplete information, and re-sample from the population to conduct a statistical comparison. Once the data has been collected or processed, it can then be summarized accurately so the decision maker can accurately interpret and compare the data.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da224a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
